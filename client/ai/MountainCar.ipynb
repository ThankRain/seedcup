{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.01  # 学习率\n",
    "EPSILON = 0.95  # 贪心策略\n",
    "GAMMA = 0.8  # 奖励衰减\n",
    "TARGET_REPLACE_ITER = 100  # 目标更新频率\n",
    "MEMORY_CAPACITY = 2000\n",
    "env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "env = env.unwrapped\n",
    "N_ACTIONS = env.action_space.n\n",
    "N_STATES = env.observation_space.shape[0]\n",
    "# ENV_A_SHAPE = 0 if isinstance(env.action_space.sample()[0], int) else env.action_space.sample().shape  # 确认形状\n",
    "print(N_STATES)\n",
    "print(N_ACTIONS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.8934,  1.4577, -0.3254, -0.2330, -0.3444, -1.5549],\n        [ 1.6870,  0.2964, -0.8691,  0.8560,  0.8739, -1.2244],\n        [-1.5050,  1.0970,  0.6678,  0.3284,  0.2981,  0.6359],\n        [ 0.8935,  1.5149,  1.0219,  1.4659, -0.3375,  1.0385]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 6)\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 0, 1, 1])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a, 1)[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class DQN(object):  # 强化神经网络\n",
    "    def __init__(self):\n",
    "        self.eval_net, self.target_net = Net(), Net()  # 定义两个网络：评估网络 & 目标网络\n",
    "        self.learn_step_counter = 0  # 用于目标网络延迟更新\n",
    "        self.memory_counter = 0  # 存储计数器\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))  # 初始化记忆全为 0\n",
    "        # 记忆单元为 当前状态 行为 奖励 操作后状态\n",
    "        # 单元数为 状态维度 * 2 + 行为维度 + 奖励维度(1)\n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)  # todo Adam 优化器\n",
    "        self.loss_func = nn.MSELoss()  # 均方误差损失函数\n",
    "\n",
    "    def choose_action(self, x):  # 传入当前的 State，计算行为\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)  # 解包\n",
    "        # 只输入一个样本\n",
    "        if np.random.uniform() < EPSILON:  # 90% 概率使用评估网络的结果\n",
    "            actions_value = self.eval_net.forward(x)  # 使用评估网络获取行为\n",
    "            # actions_value = [a1,b1,c1,d1]\n",
    "            # actions_value = [a1,b1,c1,d1]\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()  # 每行的最大值索引\n",
    "            action = action[0]  #if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n",
    "            # 返回argmax索引\n",
    "        else:  # 随机\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "            action = action  #if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n",
    "        return action\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        # print('[state]:',s)\n",
    "        # print('[action,reward]:',[a, r])\n",
    "        # print('[stated]:',s_)\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        # 用新内存替换旧内存\n",
    "        index = self.memory_counter % MEMORY_CAPACITY\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def learn(self):\n",
    "        # 目标参数更新\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # 样本批次转换\n",
    "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n",
    "        b_memory = self.memory[sample_index, :]\n",
    "        b_s = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES + 1].astype(int))\n",
    "        b_r = torch.FloatTensor(b_memory[:, N_STATES + 1:N_STATES + 2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "\n",
    "        # q_eval w.r.t体验中的行动\n",
    "        q_eval = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        q_next = self.target_net(b_s_).detach()  # detach from graph, don't backpropagate\n",
    "        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)  # shape (batch, 1)\n",
    "        loss = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(N_STATES, 1)  # 传入网络 状态数 -> 50\n",
    "        self.fc1.weight.data.normal_(0, 0.1)  # 随机初始化权重\n",
    "        self.out = nn.Linear(1, N_ACTIONS)  # 输出网络 50 -> 输出Action数\n",
    "        self.out.weight.data.normal_(0, 0.1)  # 随机初始化权重\n",
    "\n",
    "    def forward(self, x):  # 前向传播\n",
    "        x = self.fc1(x)  # 第一层映射\n",
    "        x = F.relu(x)  # 激活函数 线性整流函数 f(x) = max(0,x)\n",
    "        actions_value = self.out(x)  # 输出映射\n",
    "        return actions_value\n",
    "\n",
    "dqn = DQN()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting experience...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "轮数:  0 | 次数:  2371 | 奖励:  22.71 | 结果:  0.5369 | 速度:  0.05 | 时间:  40.19 s\n",
      "0\n",
      "100\n",
      "轮数:  1 | 次数:  178 | 奖励:  67.75 | 结果:  0.5283 | 速度:  0.0488 | 时间:  2.97 s\n",
      "0\n",
      "100\n",
      "轮数:  2 | 次数:  148 | 奖励:  66.61 | 结果:  0.5054 | 速度:  0.0492 | 时间:  2.47 s\n",
      "0\n",
      "100\n",
      "轮数:  3 | 次数:  111 | 奖励:  55.28 | 结果:  0.5009 | 速度:  0.0482 | 时间:  1.85 s\n",
      "0\n",
      "100\n",
      "轮数:  4 | 次数:  118 | 奖励:  56.51 | 结果:  0.5391 | 速度:  0.0402 | 时间:  1.97 s\n",
      "0\n",
      "轮数:  5 | 次数:  86 | 奖励:  44.07 | 结果:  0.5228 | 速度:  0.0258 | 时间:  1.43 s\n",
      "0\n",
      "100\n",
      "轮数:  6 | 次数:  116 | 奖励:  64.73 | 结果:  0.5239 | 速度:  0.0456 | 时间:  1.93 s\n",
      "0\n",
      "100\n",
      "轮数:  7 | 次数:  152 | 奖励:  74.24 | 结果:  0.5162 | 速度:  0.0485 | 时间:  2.53 s\n",
      "0\n",
      "100\n",
      "轮数:  8 | 次数:  157 | 奖励:  73.78 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.62 s\n",
      "0\n",
      "100\n",
      "轮数:  9 | 次数:  151 | 奖励:  69.7 | 结果:  0.5162 | 速度:  0.0485 | 时间:  2.52 s\n",
      "0\n",
      "轮数:  10 | 次数:  88 | 奖励:  43.36 | 结果:  0.5165 | 速度:  0.0245 | 时间:  1.47 s\n",
      "0\n",
      "100\n",
      "轮数:  11 | 次数:  161 | 奖励:  74.97 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.68 s\n",
      "0\n",
      "100\n",
      "轮数:  12 | 次数:  117 | 奖励:  60.6 | 结果:  0.5221 | 速度:  0.0438 | 时间:  1.95 s\n",
      "0\n",
      "100\n",
      "轮数:  13 | 次数:  153 | 奖励:  68.94 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.55 s\n",
      "0\n",
      "100\n",
      "轮数:  14 | 次数:  118 | 奖励:  66.3 | 结果:  0.5182 | 速度:  0.0462 | 时间:  1.97 s\n",
      "0\n",
      "轮数:  15 | 次数:  89 | 奖励:  41.9 | 结果:  0.5127 | 速度:  0.0211 | 时间:  1.48 s\n",
      "0\n",
      "轮数:  16 | 次数:  88 | 奖励:  43.27 | 结果:  0.51 | 速度:  0.0213 | 时间:  1.47 s\n",
      "0\n",
      "100\n",
      "轮数:  17 | 次数:  116 | 奖励:  59.19 | 结果:  0.5095 | 速度:  0.0363 | 时间:  1.93 s\n",
      "0\n",
      "100\n",
      "轮数:  18 | 次数:  138 | 奖励:  50.6 | 结果:  0.5187 | 速度:  0.0484 | 时间:  2.3 s\n",
      "0\n",
      "100\n",
      "轮数:  19 | 次数:  135 | 奖励:  55.08 | 结果:  0.5021 | 速度:  0.0461 | 时间:  2.25 s\n",
      "0\n",
      "100\n",
      "轮数:  20 | 次数:  139 | 奖励:  37.96 | 结果:  0.5224 | 速度:  0.0367 | 时间:  2.32 s\n",
      "0\n",
      "100\n",
      "轮数:  21 | 次数:  129 | 奖励:  41.94 | 结果:  0.5372 | 速度:  0.0458 | 时间:  2.15 s\n",
      "0\n",
      "100\n",
      "轮数:  22 | 次数:  138 | 奖励:  50.73 | 结果:  0.5041 | 速度:  0.0439 | 时间:  2.3 s\n",
      "0\n",
      "100\n",
      "轮数:  23 | 次数:  138 | 奖励:  58.01 | 结果:  0.5151 | 速度:  0.0378 | 时间:  2.3 s\n",
      "0\n",
      "100\n",
      "轮数:  24 | 次数:  131 | 奖励:  56.95 | 结果:  0.5025 | 速度:  0.0383 | 时间:  2.18 s\n",
      "0\n",
      "100\n",
      "轮数:  25 | 次数:  126 | 奖励:  53.27 | 结果:  0.5317 | 速度:  0.0455 | 时间:  2.1 s\n",
      "0\n",
      "100\n",
      "轮数:  26 | 次数:  104 | 奖励:  43.71 | 结果:  0.5093 | 速度:  0.0136 | 时间:  1.74 s\n",
      "0\n",
      "轮数:  27 | 次数:  98 | 奖励:  42.6 | 结果:  0.5153 | 速度:  0.0193 | 时间:  1.63 s\n",
      "0\n",
      "100\n",
      "轮数:  28 | 次数:  163 | 奖励:  64.55 | 结果:  0.5129 | 速度:  0.0492 | 时间:  2.72 s\n",
      "0\n",
      "100\n",
      "轮数:  29 | 次数:  108 | 奖励:  51.98 | 结果:  0.5049 | 速度:  0.0115 | 时间:  1.8 s\n",
      "0\n",
      "100\n",
      "轮数:  30 | 次数:  119 | 奖励:  52.06 | 结果:  0.5083 | 速度:  0.0226 | 时间:  1.98 s\n",
      "0\n",
      "100\n",
      "轮数:  31 | 次数:  151 | 奖励:  67.43 | 结果:  0.5335 | 速度:  0.0449 | 时间:  2.52 s\n",
      "0\n",
      "100\n",
      "轮数:  32 | 次数:  114 | 奖励:  57.24 | 结果:  0.5323 | 速度:  0.048 | 时间:  1.9 s\n",
      "0\n",
      "100\n",
      "轮数:  33 | 次数:  163 | 奖励:  75.34 | 结果:  0.5059 | 速度:  0.0494 | 时间:  2.72 s\n",
      "0\n",
      "100\n",
      "轮数:  34 | 次数:  119 | 奖励:  60.62 | 结果:  0.5068 | 速度:  0.0391 | 时间:  1.98 s\n",
      "0\n",
      "100\n",
      "轮数:  35 | 次数:  116 | 奖励:  50.6 | 结果:  0.5212 | 速度:  0.0496 | 时间:  1.93 s\n",
      "0\n",
      "轮数:  36 | 次数:  97 | 奖励:  44.89 | 结果:  0.5139 | 速度:  0.0157 | 时间:  1.62 s\n",
      "0\n",
      "100\n",
      "轮数:  37 | 次数:  101 | 奖励:  42.87 | 结果:  0.5001 | 速度:  0.0134 | 时间:  1.68 s\n",
      "0\n",
      "100\n",
      "轮数:  38 | 次数:  159 | 奖励:  75.02 | 结果:  0.5266 | 速度:  0.0464 | 时间:  2.65 s\n",
      "0\n",
      "100\n",
      "轮数:  39 | 次数:  167 | 奖励:  71.03 | 结果:  0.5205 | 速度:  0.0474 | 时间:  2.78 s\n",
      "0\n",
      "100\n",
      "轮数:  40 | 次数:  155 | 奖励:  67.72 | 结果:  0.5334 | 速度:  0.0463 | 时间:  2.58 s\n",
      "0\n",
      "100\n",
      "轮数:  41 | 次数:  141 | 奖励:  56.87 | 结果:  0.5141 | 速度:  0.0268 | 时间:  2.35 s\n",
      "0\n",
      "100\n",
      "轮数:  42 | 次数:  158 | 奖励:  55.02 | 结果:  0.5275 | 速度:  0.0473 | 时间:  2.63 s\n",
      "0\n",
      "100\n",
      "200\n",
      "轮数:  43 | 次数:  299 | 奖励:  39.73 | 结果:  0.5151 | 速度:  0.0222 | 时间:  4.98 s\n",
      "0\n",
      "100\n",
      "轮数:  44 | 次数:  140 | 奖励:  44.97 | 结果:  0.5045 | 速度:  0.0289 | 时间:  2.33 s\n",
      "0\n",
      "100\n",
      "200\n",
      "轮数:  45 | 次数:  265 | 奖励:  43.9 | 结果:  0.5181 | 速度:  0.0342 | 时间:  4.42 s\n",
      "0\n",
      "100\n",
      "轮数:  46 | 次数:  181 | 奖励:  66.75 | 结果:  0.5059 | 速度:  0.0272 | 时间:  3.02 s\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "轮数:  47 | 次数:  439 | 奖励:  80.06 | 结果:  0.5193 | 速度:  0.0479 | 时间:  7.32 s\n",
      "0\n",
      "100\n",
      "200\n",
      "轮数:  48 | 次数:  228 | 奖励:  42.06 | 结果:  0.5076 | 速度:  0.0227 | 时间:  3.8 s\n",
      "0\n",
      "100\n",
      "200\n",
      "轮数:  49 | 次数:  208 | 奖励:  25.23 | 结果:  0.506 | 速度:  0.0285 | 时间:  3.47 s\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "轮数:  50 | 次数:  1058 | 奖励:  36.28 | 结果:  0.5109 | 速度:  0.0318 | 时间:  17.64 s\n",
      "0\n",
      "100\n",
      "轮数:  51 | 次数:  143 | 奖励:  39.76 | 结果:  0.5118 | 速度:  0.0363 | 时间:  2.38 s\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "轮数:  52 | 次数:  2746 | 奖励:  39.11 | 结果:  0.5283 | 速度:  0.0312 | 时间:  45.77 s\n",
      "0\n",
      "100\n",
      "轮数:  53 | 次数:  146 | 奖励:  50.67 | 结果:  0.5219 | 速度:  0.0265 | 时间:  2.43 s\n",
      "0\n",
      "100\n",
      "轮数:  54 | 次数:  132 | 奖励:  47.17 | 结果:  0.512 | 速度:  0.0377 | 时间:  2.2 s\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "轮数:  55 | 次数:  874 | 奖励:  53.61 | 结果:  0.5037 | 速度:  0.0316 | 时间:  14.57 s\n",
      "0\n",
      "100\n",
      "轮数:  56 | 次数:  126 | 奖励:  60.85 | 结果:  0.533 | 速度:  0.0379 | 时间:  2.1 s\n",
      "0\n",
      "100\n",
      "轮数:  57 | 次数:  121 | 奖励:  64.31 | 结果:  0.5255 | 速度:  0.0435 | 时间:  2.02 s\n",
      "0\n",
      "100\n",
      "轮数:  58 | 次数:  119 | 奖励:  57.08 | 结果:  0.5177 | 速度:  0.0479 | 时间:  1.98 s\n",
      "0\n",
      "100\n",
      "轮数:  59 | 次数:  121 | 奖励:  60.48 | 结果:  0.5333 | 速度:  0.0363 | 时间:  2.02 s\n",
      "0\n",
      "100\n",
      "轮数:  60 | 次数:  165 | 奖励:  73.36 | 结果:  0.5395 | 速度:  0.0497 | 时间:  2.75 s\n",
      "0\n",
      "100\n",
      "轮数:  61 | 次数:  160 | 奖励:  73.38 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.67 s\n",
      "0\n",
      "100\n",
      "轮数:  62 | 次数:  157 | 奖励:  67.14 | 结果:  0.527 | 速度:  0.0474 | 时间:  2.62 s\n",
      "0\n",
      "100\n",
      "轮数:  63 | 次数:  160 | 奖励:  74.39 | 结果:  0.5057 | 速度:  0.0493 | 时间:  2.67 s\n",
      "0\n",
      "轮数:  64 | 次数:  90 | 奖励:  44.9 | 结果:  0.5175 | 速度:  0.024 | 时间:  1.5 s\n",
      "0\n",
      "100\n",
      "轮数:  65 | 次数:  158 | 奖励:  57.96 | 结果:  0.5215 | 速度:  0.0482 | 时间:  2.63 s\n",
      "0\n",
      "100\n",
      "轮数:  66 | 次数:  162 | 奖励:  65.5 | 结果:  0.5394 | 速度:  0.0433 | 时间:  2.7 s\n",
      "0\n",
      "100\n",
      "轮数:  67 | 次数:  165 | 奖励:  59.25 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.75 s\n",
      "0\n",
      "100\n",
      "轮数:  68 | 次数:  116 | 奖励:  56.09 | 结果:  0.5249 | 速度:  0.0358 | 时间:  1.93 s\n",
      "0\n",
      "100\n",
      "轮数:  69 | 次数:  150 | 奖励:  74.07 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.5 s\n",
      "0\n",
      "100\n",
      "轮数:  70 | 次数:  119 | 奖励:  60.1 | 结果:  0.5202 | 速度:  0.0484 | 时间:  1.98 s\n",
      "0\n",
      "100\n",
      "轮数:  71 | 次数:  126 | 奖励:  58.07 | 结果:  0.5048 | 速度:  0.0385 | 时间:  2.1 s\n",
      "0\n",
      "100\n",
      "200\n",
      "轮数:  72 | 次数:  209 | 奖励:  54.54 | 结果:  0.5341 | 速度:  0.0374 | 时间:  3.48 s\n",
      "0\n",
      "100\n",
      "轮数:  73 | 次数:  121 | 奖励:  44.09 | 结果:  0.5154 | 速度:  0.0486 | 时间:  2.02 s\n",
      "0\n",
      "100\n",
      "200\n",
      "轮数:  74 | 次数:  280 | 奖励:  44.51 | 结果:  0.5281 | 速度:  0.0346 | 时间:  4.67 s\n",
      "0\n",
      "100\n",
      "轮数:  75 | 次数:  116 | 奖励:  41.99 | 结果:  0.5032 | 速度:  0.0112 | 时间:  1.93 s\n",
      "0\n",
      "100\n",
      "轮数:  76 | 次数:  163 | 奖励:  58.52 | 结果:  0.5284 | 速度:  0.0495 | 时间:  2.72 s\n",
      "0\n",
      "100\n",
      "轮数:  77 | 次数:  153 | 奖励:  67.69 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.55 s\n",
      "0\n",
      "100\n",
      "轮数:  78 | 次数:  161 | 奖励:  78.93 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.75 s\n",
      "0\n",
      "100\n",
      "轮数:  79 | 次数:  156 | 奖励:  68.02 | 结果:  0.5245 | 速度:  0.0457 | 时间:  2.6 s\n",
      "0\n",
      "轮数:  80 | 次数:  88 | 奖励:  46.58 | 结果:  0.52 | 速度:  0.0255 | 时间:  1.47 s\n",
      "0\n",
      "100\n",
      "轮数:  81 | 次数:  162 | 奖励:  72.45 | 结果:  0.5036 | 速度:  0.0469 | 时间:  2.7 s\n",
      "0\n",
      "100\n",
      "轮数:  82 | 次数:  147 | 奖励:  70.49 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.45 s\n",
      "0\n",
      "100\n",
      "轮数:  83 | 次数:  146 | 奖励:  76.72 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.43 s\n",
      "0\n",
      "100\n",
      "轮数:  84 | 次数:  155 | 奖励:  70.69 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.58 s\n",
      "0\n",
      "100\n",
      "轮数:  85 | 次数:  153 | 奖励:  67.92 | 结果:  0.5369 | 速度:  0.05 | 时间:  2.55 s\n",
      "0\n",
      "100\n",
      "轮数:  86 | 次数:  162 | 奖励:  70.08 | 结果:  0.5476 | 速度:  0.0477 | 时间:  2.7 s\n",
      "0\n",
      "100\n",
      "轮数:  87 | 次数:  157 | 奖励:  74.91 | 结果:  0.5349 | 速度:  0.048 | 时间:  2.62 s\n",
      "0\n",
      "轮数:  88 | 次数:  87 | 奖励:  48.47 | 结果:  0.5172 | 速度:  0.025 | 时间:  1.45 s\n",
      "0\n",
      "100\n",
      "轮数:  89 | 次数:  150 | 奖励:  73.12 | 结果:  0.5447 | 速度:  0.0482 | 时间:  2.5 s\n",
      "0\n",
      "100\n",
      "轮数:  90 | 次数:  150 | 奖励:  69.44 | 结果:  0.5034 | 速度:  0.0448 | 时间:  2.5 s\n",
      "0\n",
      "100\n",
      "轮数:  91 | 次数:  145 | 奖励:  74.31 | 结果:  0.513 | 速度:  0.0454 | 时间:  2.42 s\n",
      "0\n",
      "100\n",
      "轮数:  92 | 次数:  143 | 奖励:  68.47 | 结果:  0.5308 | 速度:  0.0459 | 时间:  2.47 s\n",
      "0\n",
      "100\n",
      "轮数:  93 | 次数:  149 | 奖励:  49.93 | 结果:  0.5035 | 速度:  0.0296 | 时间:  2.48 s\n",
      "0\n",
      "100\n",
      "轮数:  94 | 次数:  158 | 奖励:  63.34 | 结果:  0.5066 | 速度:  0.0094 | 时间:  2.7 s\n",
      "0\n",
      "100\n",
      "200\n",
      "轮数:  95 | 次数:  282 | 奖励:  62.85 | 结果:  0.5003 | 速度:  0.0115 | 时间:  4.7 s\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n"
     ]
    }
   ],
   "source": [
    "print('\\nCollecting experience...')\n",
    "import time\n",
    "\n",
    "# try:\n",
    "#     print(\"读取模型中...\")\n",
    "#     dqn.target_net = torch.load(\"target.pth\")\n",
    "#     dqn.eval_net = torch.load(\"eval.pth\")\n",
    "#     print(\"读取模型成功!\")\n",
    "# except Exception as _:\n",
    "#     print(\"读取模型失败!\")\n",
    "flag = True\n",
    "for i_episode in range(400):\n",
    "    if flag:\n",
    "        s = env.reset()\n",
    "        ep_r = 0\n",
    "        times = 0\n",
    "        start = time.time()\n",
    "        max_x = -1.2\n",
    "        min_x = 0.6\n",
    "        while True:\n",
    "            try:\n",
    "                env.render()\n",
    "                a = dqn.choose_action(s)\n",
    "                # if x >= 0.0 and v <= 0.0:  # 右边下滑\n",
    "                #     a = 0  # 向左加速\n",
    "                # elif x >= 0.0 and v > 0.0:  # 右边上冲\n",
    "                #     a = 2  # 向右加速\n",
    "                # elif x < 0.0 and v >= 0.0:  # 左边下滑\n",
    "                #     a = 2  # 向右加速\n",
    "                # elif x < 0.0 and v < 0.0:  # 左边上冲\n",
    "                #     a = 0  # 向左加速\n",
    "                # take action\n",
    "                s_, r, done, info = env.step(a)\n",
    "                x, v = s_\n",
    "                # if x > -0.5:\n",
    "                #     r = abs(x * 5)\n",
    "                # else:\n",
    "                #     r = abs(x * 5)\n",
    "                # r = (r * 1000) / times\n",
    "                # x = x + 0.5\n",
    "                if x >= 0.0 and v <= 0.0:  # 右边下滑\n",
    "                    if a == 0:  # 向左加速\n",
    "                        r = x\n",
    "                    else:\n",
    "                        r = -x\n",
    "                elif x >= 0.0 and v > 0.0:  # 右边上冲\n",
    "                    if a == 2:  # 向右加速\n",
    "                        r = x\n",
    "                    else:\n",
    "                        r = -x\n",
    "                elif x < 0.0 and v >= 0.0:  # 左边下滑\n",
    "                    if a == 2:  # 向右加速\n",
    "                        r = -x\n",
    "                    else:\n",
    "                        r = x\n",
    "                elif x < 0.0 and v < 0.0:  # 左边上冲\n",
    "                    if a == 0:  # 向左加速\n",
    "                        r = -x\n",
    "                    else:\n",
    "                        r = x\n",
    "                # if a == 1:\n",
    "                #     r = 0\n",
    "                # r = x\n",
    "                if x > max_x: max_x = x\n",
    "                if x < min_x: min_x = x\n",
    "                if times % 100 == 0:\n",
    "                    print(times)\n",
    "                #     print('[', times, ']{(x,r):(', round(x, 2), ',', round(r, 2), ')},{range:[', round(min_x, 2), ',',\n",
    "                #           round(max_x, 2), ']}')\n",
    "                times += 1\n",
    "                # print(str(times) + \":\" + str(r))\n",
    "                # r1 = (env.x_threshold - abs(x)) / env.x_threshold - 0.8\n",
    "                # r2 = (env.theta_threshold_radians - abs(theta)) / env.theta_threshold_radians - 0.5\n",
    "                # r = r1 + r2\n",
    "\n",
    "                dqn.store_transition(s, a, r, s_)\n",
    "\n",
    "                ep_r += r\n",
    "                if dqn.memory_counter > MEMORY_CAPACITY:\n",
    "                    dqn.learn()\n",
    "                    if done:\n",
    "                        t = time.time() - start\n",
    "                        print('轮数: ', i_episode,\n",
    "                              '| 次数: ', round(times, 2),\n",
    "                              '| 奖励: ', round(ep_r, 2),\n",
    "                              '| 结果: ', round(x, 4),\n",
    "                              '| 速度: ', round(v, 4),\n",
    "                              '| 时间: ', round(t, 2), 's'\n",
    "                              )\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "                s = s_\n",
    "            except KeyboardInterrupt as e:\n",
    "                flag = False\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"保存模型中...\")\n",
    "torch.save(dqn.target_net, \"target.pth\")\n",
    "torch.save(dqn.eval_net, \"eval.pth\")\n",
    "print(\"保存成功，程序已退出\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test():\n",
    "    s = env.reset()\n",
    "    ep_r = 0\n",
    "    times = 0\n",
    "    start = time.time()\n",
    "    max_x = -1.2\n",
    "    min_x = 0.6\n",
    "    while True:\n",
    "        try:\n",
    "            # env.render()\n",
    "            a = dqn.choose_action(s)\n",
    "            s_, r, done, info = env.step(a)\n",
    "            x, v = s_\n",
    "            # r = x\n",
    "            if x > max_x: max_x = x\n",
    "            if x < min_x: min_x = x\n",
    "            # if times % 10 == 0:\n",
    "            #     print('[', times, ']{(x,v):(', round(x, 2), ',', round(v, 2), ')},{range:[', round(min_x, 2), ',',\n",
    "            #           round(max_x, 2), ']}')\n",
    "            times += 1\n",
    "            ep_r += r\n",
    "            if done:\n",
    "                t = time.time() - start\n",
    "                print('次数: ', round(times, 2),\n",
    "                      '| 结果: ', round(x, 4),\n",
    "                      '| 速度: ', round(v, 4),\n",
    "                      '| 时间: ', round(t, 2), 's'\n",
    "                      )\n",
    "                return times\n",
    "            s = s_\n",
    "        except KeyboardInterrupt as e:\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"读取模型中...\")\n",
    "    dqn.target_net = torch.load(\"target.pth\")\n",
    "    dqn.eval_net = torch.load(\"eval.pth\")\n",
    "    print(\"读取模型成功!\")\n",
    "except Exception as _:\n",
    "    print(\"读取模型失败!\")\n",
    "t = 0\n",
    "for _ in range(0,20):\n",
    "    t += test()\n",
    "print(\"累计次数: \",t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"读取模型中...\")\n",
    "    dqn.target_net = torch.load(\"../target.pth\")\n",
    "    dqn.eval_net = torch.load(\"../eval.pth\")\n",
    "    print(\"读取模型成功!\")\n",
    "except Exception as _:\n",
    "    print(\"读取模型失败!\")\n",
    "t = 0\n",
    "for _ in range(0,20):\n",
    "    t += test()\n",
    "print(\"累计次数: \",t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
